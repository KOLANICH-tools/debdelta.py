#!/usr/bin/python
"""
debforensic

A program to create a database of hashes of files in Debian packages,
and to check for file alterations in an installed host.

Copyright (c) 2007 A. Mennucci
License: GNU GPL v2

"""

import sys
import os
import tempfile
import string
import getopt
import tarfile
import shutil
import time
import traceback
import stat
import pwd
import grp

from stat import ST_SIZE, ST_MTIME, ST_MODE, ST_INO, ST_DEV, S_IMODE, S_IRUSR, S_IWUSR, S_IXUSR
from os.path import abspath
from copy import copy
from types import IntType, StringType, FunctionType, TupleType, ListType, DictType, BufferType

try:
    from pysqlite2 import dbapi2 as dbapi
except ImportError:
    dbapi = None

try:
    import hashlib
    md5new = hashlib.md5
    sha1new = hashlib.sha1
    sha256new = hashlib.sha256
except ImportError:
    import sha
    import md5
    md5new = md5.new
    sha1new = sha.sha
    sha256new = None


# multi hash support
# it makes for *huge* databases, with
# no clear benefit
# It is the 'or' of the flag in all linked databases (see 'hashdb' class)
multi_hash_p = False


__help__usage__ = "Usage: debforensic [OPTION]... "
__help__options__ = {
    "db": "--db DB   -D  DB\nis the sqlite database file storing package file hashes (this option is mandatory!)",
    "verbose": "-v   --verbose\nbe verbose, print more informations",
    "recursive": "-r --recursive\nrecurse in directories",
    "chroot": "--chroot ROOT\napply command to filesystem inside the ROOT",
    "info": "-i --info\nexplain the return codes when each is first seen"
}
# -R
# --release RELEASE
# is the Debian Release file,
#-d   --debug
#      print debugging info (not really useful but for the program author)


__help__ = {
    None: __help__usage__ + """[COMMAND] [ARGS]..\n
 [command]  may be one of --create --add --dump --scan --index --forensic \n
Use -h [command] for further help on commands""",

    "create": __help__usage__ + """--create [ARGS]\n
Creates the sqlite database file DB that is used to store packages' info.\n
Example of ARGS are a list of Debian packages, or a `Packages' file, such as
 dist/stable/main/binary-i386/Packages (that is found in a Debian mirror or CD).""",

    "scan": __help__usage__ + """--scan [files and directories]...\n
Scans provided files and directories, for each match prints a line of the form
return_code file some_optional_info (package, version, architecture)""",

    "add": __help__usage__ + """--add  [debian packages]\n\n
Computes checksums for provided Debian packages and stores it in database""",

    "forensic": __help__usage__ + """--forensic\n
Scans the entire filesystem tree, checks each file against
the list of (supposedly) installed packages, and against
the database.""",

    "index": __help__usage__ + """--index\n
    Adds SQL indexes to the database DB. This speeds up
operations such as --scan and --forensic.\n
Note that indexing requires a lot of time;
and as much free space in your harddisk as the DB is large;
and eventually it may double the size of the DB file.""",

    "compress": __help__usage__ + """--compress\n
Compress some data inside the database DB , to reduce its file size.\n
Note that this operation requires a lot of time,
and as much free space in your harddisk as the DB is large.""",

    "dump": __help__usage__ + " --show\n\
show the content of the whole database as a tab separated list.",

    # these are actually not advertised in documentation
    "select": __help__usage__ + """ --select [SQL]
Returns a SQL query to the database. Examples "select md5 = ..." """,
    "test": __help__usage__ + " --test\n perform a simple test"
}


def help(cmd=None):
    if cmd and cmd[:2] == '--':
        cmd = cmd[2:]
    sys.stderr.write(__help__.get(cmd, " UNKNOWN COMMAND ") + "\n")
    if cmd:
        sys.stderr.write("\nOptions:\n  " + string.join(__help__options__.values(), "\n  ") + "\n")


if dbapi is not None:
    # ===== sqlite machinery
    def convert_blob(s):
        return s  # this is always a string

    # Register the adapter
    #sqlite.register_adapter(StringType, adapt_blob)

    # Register the converter
    dbapi.register_converter("blob", convert_blob)
    dbapi.register_converter("text", convert_blob)


def de_n(a):
    if a and a[-1] == '\n':
        a = a[:-1]
    return a

# ============ code to compress filename prefixes
# TODO adapt to the real data


class CompressFilename:
    common_file_prefixes = ('',  # null pathname, code=0
                            'usr/',
                            'usr/share/',
                            'usr/share/doc/',
                            'usr/lib/',
                            'usr/share/locale/',
                            'usr/share/man/',
                            'usr/share/games/',
                            'usr/include/',
                            'usr/share/doc/kde/HTML/',
                            'usr/src/',
                            'usr/share/icons/',
                            'var/',
                            'var/lib/',
                            'usr/lib/openoffice/',
                            'usr/share/texmf/',
                            'lib/',
                            'lib/modules/',
                            'etc/',
                            'sbin/',
                            'bin/')

    excluded_file_prefixes = ('proc/', 'sys/', 'home/', 'usr/local/', 'dev/')

    def compressor(self, pref, excl=(), startcode=0):
        def recurse(code):  # local recursive function
            tree = {}
            p = {}
            for a, j in code:
                if len(a) > 1:
                    p[a[0]] = p.get(a[0], []) + [(a[1:], j), ]
                elif len(a) == 1:
                    if a[0] == '':
                        tree[a[0]] = j
                    else:
                        p[a[0]] = p.get(a[0], []) + [('', j), ]
                else:
                    tree[''] = j
            for l, r in p.items():
                # if len(r)==1:
                #    a,j=r[0]
                #    tree[l]=j#but this reduced efficency
                # else:
                tree[l] = recurse(r)
            return tree
        code_n = []
        for a in pref:
            assert a == '' or a[-1] == '/'
            code_n.append((a.split('/'), startcode))
            startcode = startcode + 1
        self.last_code_n = startcode - 1
        tree = recurse(code_n)
        for j in excl:
            assert j[-1] == '/'
            a = j[:-1].split('/')
            b = tree
            while len(a) > 1 and a[0] in b and isinstance(b[a[0]], DictType):
                b = b[a[0]]
                a = a[1:]
            b[a[0]] = None
        return tree
        # embedded recursive function

    def __init__(self):
        self.code_tree = self.compressor(self.common_file_prefixes, self.excluded_file_prefixes)
        # assert self.last_code_n < 31 #should be non printable ascii

    def find_prefix(self, f, tree=None):
        if tree is None:
            tree = self.code_tree
        a = f.split('/')
        res = tree.get('')  # uncodable code result
        while len(a) > 0:
            res = tree.get('', res)
            if a[0] == '':
                assert len(a) == 1  # I hate // in pathnames
                return res
            elif a[0] in tree:
                tree = tree[a[0]]
                a = a[1:]
                if tree is None:
                    return None  # this filename is excluded
            else:
                return res
        return res

    def compress(self, name):
        assert isinstance(name, StringType)
        n = self.find_prefix(name)
        if n is None:
            print '# Warning , filename: ' + repr(name) + ' should not be present in a .deb'
            return ('%c' % (1)) + name
        # if n != 0:
        p = self.common_file_prefixes[n]
        # avoid 0, may look like a null terminated string
        f = ('%c' % (n + 1)) + name[len(p):]
        return f

    def decompress(self, name):
        assert isinstance(name, StringType)
        # avoid 0, may look like a null terminated string
        n = ord(name[0]) - 1
        p = self.common_file_prefixes[n]
        f = p + name[1:]
        return f

    def test(self):
        for name in ('', 'initrd', 'etc', 'etc/', 'etc/conf', 'usr', 'usr/local/', 'sbin/gino',
                     'usr/share/', 'usr/share/doc', 'usr/share/doc/',
                     'usr/share/doc/kde/', 'usr/share/doc/kde/HTML'):
            n = self.find_prefix(name)
            c = self.compress(name)
            d = self.decompress(c)
            print 'Test compressing ', repr(name), n, repr(c), repr(d)
            assert name == d


# ===== code to convert 'stat() file info' <-> 'tar file info' <-> 'sqlite file info'


# in base-passwd 3.5.11
# /usr/share/base-passwd/passwd.master
base_passwd = """root::0:0:root:/root:/bin/bash
daemon:*:1:1:daemon:/usr/sbin:/bin/sh
bin:*:2:2:bin:/bin:/bin/sh
sys:*:3:3:sys:/dev:/bin/sh
sync:*:4:65534:sync:/bin:/bin/sync
games:*:5:60:games:/usr/games:/bin/sh
man:*:6:12:man:/var/cache/man:/bin/sh
lp:*:7:7:lp:/var/spool/lpd:/bin/sh
mail:*:8:8:mail:/var/mail:/bin/sh
news:*:9:9:news:/var/spool/news:/bin/sh
uucp:*:10:10:uucp:/var/spool/uucp:/bin/sh
proxy:*:13:13:proxy:/bin:/bin/sh
www-data:*:33:33:www-data:/var/www:/bin/sh
backup:*:34:34:backup:/var/backups:/bin/sh
list:*:38:38:Mailing List Manager:/var/list:/bin/sh
irc:*:39:39:ircd:/var/run/ircd:/bin/sh
gnats:*:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/bin/sh
nobody:*:65534:65534:nobody:/nonexistent:/bin/sh"""
base_passwd_db = {}
base_passwd_anti_db = {}
for a in base_passwd.split('\n'):
    a = a.split(':')
    base_passwd_db[a[0]] = int(a[2])
    base_passwd_anti_db[int(a[2])] = a[0]

base_group = """root:*:0:
daemon:*:1:
bin:*:2:
sys:*:3:
adm:*:4:
tty:*:5:
disk:*:6:
lp:*:7:
mail:*:8:
news:*:9:
uucp:*:10:
man:*:12:
proxy:*:13:
kmem:*:15:
dialout:*:20:
fax:*:21:
voice:*:22:
cdrom:*:24:
floppy:*:25:
tape:*:26:
sudo:*:27:
audio:*:29:
dip:*:30:
www-data:*:33:
backup:*:34:
operator:*:37:
list:*:38:
irc:*:39:
src:*:40:
gnats:*:41:
shadow:*:42:
utmp:*:43:
video:*:44:
sasl:*:45:
plugdev:*:46:
staff:*:50:
games:*:60:
users:*:100:
nogroup:*:65534:"""

base_group_db = {}
base_group_anti_db = {}
for a in base_group.split('\n'):
    a = a.split(':')
    base_group_db[a[0]] = int(a[2])
    base_group_anti_db[int(a[2])] = a[0]

# all code following return name,mode,tartype,uid,gid,uname,gname

# adapted from tarfile.py, a Python module


def stat_to_tar(name):
    statres = os.lstat(name)
    stmd = statres.st_mode
    data = None
    if stat.S_ISREG(stmd):
        type = tarfile.REGTYPE
        # here ideally we should SHA1 the file ;
        # but this is done elsewhere for performance,
        # and to have multi_hash in the future
    elif stat.S_ISDIR(stmd):
        type = tarfile.DIRTYPE
    elif stat.S_ISFIFO(stmd):
        type = tarfile.FIFOTYPE
    elif stat.S_ISLNK(stmd):
        type = tarfile.SYMTYPE
        data = os.readlink(name)
    elif stat.S_ISCHR(stmd):
        type = tarfile.CHRTYPE
    elif stat.S_ISBLK(stmd):
        type = tarfile.BLKTYPE
    elif stat.S_ISSOCK(stmd):
        type = 'SOCKET'  # SOCKETs are not supported in tar files
    else:
        raise TypeError

    if type in (tarfile.CHRTYPE, tarfile.BLKTYPE):
        data = str(os.major(statres.st_rdev)) + ' ' + str(os.minor(statres.st_rdev))

    uid, gid = statres.st_uid, statres.st_gid

    if uid in base_passwd_anti_db:
        uname = base_passwd_anti_db[uid]
    else:
        try:
            uname = pwd.getpwuid(uid)[0]
        except KeyError:
            uname = None

    if gid in base_group_anti_db:
        gname = base_group_anti_db[gid]
    else:
        try:
            gname = grp.getgrgid(gid)[0]
        except KeyError:
            gname = None

    # 07777 is used in tarfile.TarInfo.tobuf
    return name.lstrip('/'), stmd & 0o7777, type, uid, gid, uname, gname, data


def helper_hashes(i, m=multi_hash_p):
    "helper to compute hashes only once in scan() or forensic()"
    assert isinstance(i, StringType)
    if os.path.isfile(i) and not os.path.islink(i):
        if m:
            return multi_hash_file(i)
        else:
            return (None, sha1_hash_file(i), None)
    else:
        return (None, None, None)


def tarinfo_to_ls(tartype, tarmode):
    "returns a string -rwxrwxrwx such as what ls -l prints "
    if ord(tartype) == 0:
        a = '_'
    else:
        if tartype >= '0' and tartype <= '6':
            a = "-hlcbdp"[ord(tartype) - ord('0')]
        else:
            a = '?'
    return a + tarfile.filemode(tarmode)[1:]


def tarinfo_to_sqlite(tarinfo, CF, package_name=''):
    tartype = tarinfo.type
    mode = tarinfo.mode
    B = dbapi.Binary

    if tartype == tarfile.AREGTYPE:
        tartype = tarfile.REGTYPE

    if tartype == tarfile.SYMTYPE:
        if (mode == 0o777 or mode == 0o120777):
            mode = None
        else:
            print 'WEIRD_SYMLINK ', tarinfo.name, ' WITH MODE = ', '0%o' % mode, package_name

    if (tartype == tarfile.REGTYPE or tartype == tarfile.DIRTYPE) \
       and mode == 0o755:
        mode = None

    if tarinfo.uname in base_passwd_db and tarinfo.uid == base_passwd_db[tarinfo.uname]:
        uname = None
    else:
        print 'NON_STANDARD uname ', repr(tarinfo.uname), ' for ', tarinfo.name, package_name
        uname = B(tarinfo.uname)

    if tarinfo.gname in base_group_db and tarinfo.gid == base_group_db[tarinfo.gname]:
        gname = None
    else:
        print 'NON_STANDARD gname ', repr(tarinfo.gname), ' for ', tarinfo.name, package_name
        gname = B(tarinfo.gname)

    name = tarinfo.name
    if name[:2] == './':
        name = name[2:]

    if CF:
        name = CF.compress(name)

    return dbapi.Binary(name), mode, dbapi.Binary(tartype), tarinfo.uid, tarinfo.gid, uname, gname


def sqlite_towards_tarinfo(r, CF):
    "unpacks a  SELECT name,mode,tartype,uid,gid,uname,gname,other_data,package_id FROM file"
    assert isinstance(r, TupleType) or isinstance(r, ListType)
    if len(r) == 9:
        name, mode, tartype, uid, gid, uname, gname, other_data, package_id = r
    else:
        assert Exception, 'unimplemented'

    if isinstance(tartype, BufferType):
        tartype = str(tartype)

    # undo some simplifications done above
    if tartype == tarfile.SYMTYPE and mode is None:
        mode = 0o777

    if (tartype == tarfile.REGTYPE or tartype == tarfile.DIRTYPE) \
       and mode is None:
        mode = 0o755

    if tartype == tarfile.SYMTYPE and mode is None:
        mode = 0o777

    assert isinstance(mode, IntType) and isinstance(uid, IntType) \
        and isinstance(gid, IntType) and isinstance(package_id, IntType)

    if isinstance(other_data, BufferType):
        other_data = str(other_data)

    if uname is None:
        uname = base_passwd_anti_db[uid]
    elif isinstance(uname, BufferType):
        uname = str(uname)

    if gname is None:
        gname = base_group_anti_db[gid]
    elif isinstance(gname, BufferType):
        gname = str(gname)

    name = CF.decompress(str(name))

    return name, mode, tartype, uid, gid, uname, gname, other_data, package_id

#########################################


sql_scheme = """
create table package (
id integer unique primary key autoincrement,
name text,
version text,
architecture text,
hash data ) ;

create table file (
/* 'id' is  currently useless, but SQL would create it internally nonetheless*/
id integer unique primary key autoincrement,
name blob,
mode integer,
tartype integer,
uid integer,
gid integer,
uname text,
gname text,
package_id integer ,
other_data data) ;

create table info(
key text,
data blob);
"""

sql_scheme_indexes = """
CREATE INDEX IF NOT EXISTS package_hash ON package ( hash );
CREATE INDEX IF NOT EXISTS file_package_id ON file ( package_id );
CREATE INDEX IF NOT EXISTS file_data ON file ( other_data );
CREATE INDEX IF NOT EXISTS file_name ON file (name);
"""

# if multi hash support
if multi_hash_p:
    sql_scheme += """
create table hash (
id integer unique primary key autoincrement,
sha1 blob ,
md5 blob ,
sha256 blob ,
len integer) ;
CREATE INDEX sha1 ON hash ( sha1 );
"""


def scan_diversions():
    f = open('/var/lib/dpkg/diversions')
    diversions_from = {}
    diversions_to = {}
    while True:
        divert_from = f.readline()
        if not divert_from:
            break
        divert_from = divert_from.rstrip('\n').lstrip('/')
        divert_to = f.readline().rstrip('\n').lstrip('/')
        divert_package = f.readline().rstrip('\n')
        diversions_from[divert_from] = (divert_to, divert_package)
        diversions_to[divert_to] = (divert_from, divert_package)
    f.close()
    return diversions_from, diversions_to


def parse_status(ROOT, DBs):
    installed_packages = {}
    ok = False
    local = 0
    for l in open(ROOT + 'var/lib/dpkg/status'):
        l = l.rstrip('\n')
        if l[:9] == 'Package: ':
            pack = l[9:]
        elif l == 'Status: install ok installed':
            ok = True
        elif l[:14] == 'Architecture: ':
            arch = l[14:]
        elif l[:9] == 'Version: ':
            vers = l[9:]
        elif l == '':
            if ok:
                db = None
                for d in DBs:
                    r = d.find_package_id(pack, vers, arch)
                    if r is not None:
                        db = d
                        break
                if r is not None:
                    installed_packages[(r[0], db.dbname)] = (pack, vers, arch)
                else:
                    local = local + 1
                    if DEBUG or VERBOSE:
                        print '# installed package not in databases: ', pack, vers, arch
                    for a in open(ROOT + 'var/lib/dpkg/info/' + pack + '.list'):
                        a = a.lstrip('/').rstrip('\n')
                        installed_packages[a] = (pack, vers, arch)
            ok = False
    if local:
        print '# there are %d installed package not in database(s)' % local
    return installed_packages


def parse_release(RELEASE_FILE):
    hash = None
    DB = {}
    for a in open(RELEASE_FILE):
        a = de_n(a)
        if ':' in a:
            a = a.split(':')
            if a[1]:
                DB[a[0]] = a[1][1:]
            else:
                hash = a[0]
        elif a[0] == ' ':
            a = [i for i in a[1:].split(' ') if i]
            DB[a[-1]] = (hash, a[0])
        else:
            print '(Did not parse', RELEASE_FILE, a
    return DB


def sha1_hash_file(f):
    if isinstance(f, StringType):
        try:
            f = open(f)
        except IOError:
            return None
    a = f.read(1024)
    s1 = sha1new()
    while a:
        s1.update(a)
        a = f.read(1024)
    f.close()
    return s1.digest()


def sha1_to_hex(s):
    a = ''
    for i in s:
        a = a + ('%02x' % ord(i))
    return a

# this is used onl if multi hash


def multi_hash_file_wo_sha256(f):
    if isinstance(f, StringType):
        f = open(f)
    a = f.read(1024)
    m = md5new()
    s1 = sha1new()
    while a:
        m.update(a)
        s1.update(a)
        a = f.read(1024)
    f.close()
    return (m.digest(), s1.digest())
# this is used onl if multi hash


def multi_hash_file(f):
    if isinstance(f, StringType):
        try:
            f = open(f)
        except IOError:
            return (None, None, None)
    a = f.read(1024)
    m = md5new()
    s1 = sha1new()
    if sha256new:
        s256 = sha256new()
    while a:
        m.update(a)
        s1.update(a)
        if sha256new:
            s256.update(a)
        a = f.read(1024)
    f.close()
    if sha256new:
        return (m.digest(), s1.digest(), s256.digest())
    else:
        return (m.digest(), s1.digest(), None)


def scan_control(p):
    if isinstance(p, StringType):
        p = os.popen('env -i dpkg-deb -I ' + p)
    params = {}
    for a in p:
        if a[:2] == '  ':
            continue
        if a[0] == ' ':
            a = a[1:]
        a = de_n(a)
        if a[:4] in ('Pack', 'Vers', 'Arch', 'Stat', 'Inst', 'File'):
            i = a.index(':')
            assert(a[i:i + 2] == ': ')
            params[a[:i]] = a[i + 2:]
    return params


# ==== this class manages connection to the sqlite db
class hashdb:
    dbname = None
    sql_connection = None
    sql_cursor = None
    __cp = None
    __cf = None
    __cf = None
    multi_hash_p = False
    sql_master = {}

    # what to present of a package
    package_info = 'name,version,architecture'

    def __init__(self, dbname):
        assert isinstance(dbname, StringType)
        assert os.path.exists(dbname)
        self.dbname = dbname
        self.sql_connection = dbapi.connect(dbname,
                                            detect_types=dbapi.PARSE_DECLTYPES | dbapi.PARSE_COLNAMES)

        self.sql_master = {}

        self.sql_cursor = self.sql_connection.cursor()

        self.sql_cursor.execute('SELECT * FROM SQLITE_MASTER ')
        r = self.sql_cursor.fetchone()
        while r:
            self.sql_master[r[1]] = r
            r = self.sql_cursor.fetchone()

        self.multi_hash_p = 'hash' in self.sql_master
        global multi_hash_p
        multi_hash_p = multi_hash_p or self.multi_hash_p

        self.__ch = self.sql_connection.cursor()
        self.__cp = self.sql_connection.cursor()
        self.__cf = self.sql_connection.cursor()

        self.CF = CompressFilename()

    def __del__(self):
        self.sql_connection.close()

    def commit(self):
        self.sql_connection.commit()

    def insert_info(self, A, B):
        self.sql_cursor.execute('INSERT INTO info VALUES (?, ?)', (A, dbapi.Binary(B)))
        self.sql_connection.commit()

    def replace_info(self, A, B):
        self.sql_cursor.execute('SELECT * FROM info WHERE key = ?', (A,))
        r = self.sql_cursor.fetchone()
        if r:
            self.sql_cursor.execute('REPLACE INTO info VALUES (?, ?) WHERE key = ?',
                                    (A, dbapi.Binary(B), A))
        else:
            self.sql_cursor.execute('INSERT INTO info VALUES (?, ?)', (A, dbapi.Binary(B)))
        self.sql_connection.commit()

    def get_info(self, A):
        self.sql_cursor.execute('SELECT * FROM info WHERE key = ?', (A,))
        r = self.sql_cursor.fetchone()
        assert r[0] == A
        return r[1]

    def dump_flat_all(self):
        if self.multi_hash_p:
            return self.sql_cursor.execute('SELECT package.name, package.version, package.architecture, file.name, file.mode, file.tartype FROM package, file WHERE file.package_id = package.id ;')
        else:
            return self.sql_cursor.execute('SELECT package.name, package.version, package.architecture, file.name, file.mode, file.tartype, file.uid, file.gid, file.uname, file.gname, file.other_data, file.package_id FROM package, file WHERE file.package_id = package.id  ;')

    # this part is only used if the database is multihash
    #   that is, there is a 'hash' table storing (md5,sha1,sha256,len)
    #  in the following, m = (md5,sha1,sha256)

    def select_by_hash_sha1_(self, m):
        "returns the id of the row matching sha1. Checks only sha1 hash."
        assert self.multi_hash_p
        self.sql_cursor.execute('SELECT id FROM hash WHERE sha1=? ', (dbapi.Binary(m[1]),))
        r = self.sql_cursor.fetchall()
        if r is None:
            return None
        if len(r) > 1:
            sys.write.stderr('INTERNAL ERROR in database ', self.filename, ' multiple sha1 equal to row id=', r[0][0])
        return r[0][0]

    def select_hash_by_id(self, id):
        assert self.multi_hash_p
        self.__ch.execute('SELECT md5,sha1,sha256 FROM hash WHERE id = ? ', (id,))
        r = self.__ch.fetchone()
        if r is None:
            sys.stderr.write('INTERNAL.PROBLEM.no.hash.for.id' + id)
            return (None, None, None)
        return r

    def select_and_check_by_hashes(self, m):
        "returns the id of row in the table 'hash' matching m. Checks all hashes. Works only with multi hash dbs"
        md5, sha1, sha256 = m
        assert self.multi_hash_p and md5 is not None and sha256 is not None
        self.sql_cursor.execute('SELECT id,md5,sha256 FROM hash WHERE sha1=? ', (dbapi.Binary(sha1),))
        r = self.sql_cursor.fetchall()
        if r is None:
            return None
        if len(r) > 1:
            sys.write.stderr('INTERNAL ERROR in database ', self.filename, ' multiple sha1 equal to row id=', r[0][0])
        r = r[0]
        assert md5 == r[1] and sha256 == r[2]
        return r[0]

    def insert_hash__(self, h, l):
        self.sql_cursor.execute('INSERT INTO hash  VALUES (none,?,?,?,?)', (map(dbapi.Binary, h) + (l,)))
        return self.sql_cursor.lastrowid

    def insert_hash(self, h, l):
        "if the hash is already there, just return the (first) row id"
        r = self.select_by_hash_sha1_(h)
        if r is not None:
            return r
        return self.insert_hash__(h, l)
    # end of section regarding multi hash db

    def hash_deb(self, name, RELEASE_DB={}):
        if self.multi_hash_p:
            h = multi_hash_file(name)
            deb_hash = self.select_by_hash_sha1_(h)
            if deb_hash is not None:
                if VERBOSE > 1:
                    print 'ALREADY_ADDED ', name
                return deb_hash
            else:
                deb_hash = self.insert_hash(h, os.stat(name)[ST_SIZE])
        else:
            # be sure to insert as blob!
            deb_hash = dbapi.Binary(sha1_hash_file(name))
            self.sql_cursor.execute('SELECT id FROM package WHERE hash=? ', (deb_hash,))
            r = self.sql_cursor.fetchall()
            if len(r) > 1 and VERBOSE > 1:
                print 'MULTIPLY_ADDED ', name
                return r[0]
            if r:
                if VERBOSE > 1:
                    print 'ALREADY_ADDED ', name
                return r[0]

        c = scan_control(name)
        self.sql_cursor.execute('INSERT INTO package VALUES (null, ?, ?, ?, ?)',
                                (c['Package'], c['Version'], c['Architecture'], deb_hash))
        deb_id = self.sql_cursor.lastrowid
        #f = os.open('ar p '+name+' data.tar.gz')
        #system('ar p '+deb+' control.tar.gz | tar -x -z -p -f - -C '+TD+'OLD/CONTROL',TD)
        f = os.popen('dpkg --fsys-tarfile ' + name)
        t = tarfile.open(name, 'r|', f)
        self.hash_tar(t, deb_id, name)
        self.sql_connection.commit()
        if VERBOSE:
            print 'ADDED ', name
        return deb_id

    def hash_tar(self, tar, package_id, package_name):
        B = dbapi.Binary
        for tarinfo in tar:
            # skip plain dirs
            if tarinfo.isdir():
                #p=tarinfo_to_ls(tarinfo.type,tarinfo.mode) +( '0%o'%tarinfo.mode)
                if (tarinfo.mode == 0o755 or tarinfo.mode == 0o40755) and \
                   tarinfo.uname == 'root' and tarinfo.gname == 'root':
                    if VERBOSE > 1:
                        print 'SKIP', tarinfo_to_ls(tarinfo.type, tarinfo.mode),\
                            tarinfo.uname, tarinfo.gname, tarinfo.name, package_name
                    continue
                n = self.CF.find_prefix(tarinfo.name)
                if n is None:
                    print 'NON_POLICY_DIR', ('0%o' % tarinfo.mode),\
                        tarinfo.uname, tarinfo.gname, tarinfo.name, package_name
                elif n != 0 and n is not None and tarinfo.name == self.CF.common_file_prefixes[n]:
                    print 'SKIP_STRANGE_DIR', ('0%o' % tarinfo.mode),\
                        tarinfo.uname, tarinfo.gname, tarinfo.name, package_name
                    continue
            # prepare data
            if tarinfo.isreg():
                f = tar.extractfile(tarinfo)
                if self.multi_hash_p:
                    data = self.insert_hash(h, tarinfo.size)
                else:
                    data = B(sha1_hash_file(f))
            elif tarinfo.issym() or tarinfo.islnk():
                data = B(tarinfo.linkname)
            elif tarinfo.ischr() or tarinfo.isblk():
                data = B(str(tarinfo.devmajor) + ' ' + str(tarinfo.devminor))
            else:
                data = None
            name, mode, tartype, uid, gid, uname, gname = tarinfo_to_sqlite(tarinfo, self.CF, package_name)
            # insert regularized data
            self.sql_cursor.execute('INSERT INTO file VALUES (null, ?, ?, ?, ?, ?, ?, ?, ?, ?)',
                                    (name, mode, tartype, uid, gid, uname, gname,
                                     package_id, data))
            if VERBOSE > 1:
                a = str(data)
                if tarinfo.isreg() and not self.multi_hash_p:
                    a = 'SHA1:' + sha1_to_hex(data)
                print ' ', tarinfo_to_ls(tarinfo.type, tarinfo.mode), tarinfo.name, a

    def add(self, i):
        if isinstance(i, ListType):
            for a in i:
                self.add(a)
        elif isinstance(i, StringType):
            if os.path.isfile(i) and i[-4:] == '.deb':
                self.hash_deb(i)
            elif os.path.isdir(i):
                for dirpath, dirnames, filenames in os.walk(i):
                    for n in filenames:
                        self.add(os.path.join(dirpath, n))
        else:
            raise TypeError('add accepts only strings (filenames) or lists of filenames')

    def select_package_by_id(self, id):
        self.__cp.execute('SELECT ' + self.package_info + ' FROM package  WHERE id = ? ', (id,))
        rp = self.__cp.fetchone()
        if rp is None:
            sys.stderr.write('INTERNAL.PROBLEM.no.package.for.' + id)
        return rp

    def find_package_id(self, pack, vers, arch):
        self.__cp.execute("SELECT id FROM package  WHERE name = ? AND version = ? AND architecture = ? ",
                          (pack, vers, arch))
        #self.__cp.execute("SELECT id FROM package  WHERE name =  ?", (pack,))
        rp = self.__cp.fetchone()
        return rp

    def find_by_sha1(self, s):
        "returns a filename,package,version,arch matching the given sha1"
        if self.multi_hash_p:
            assert False
            hash_id = self.select_by_hash_sha1_((None, s, None))
        else:
            self.__cf.execute('SELECT name,package_id FROM file  WHERE other_data = ? ',
                              (dbapi.Binary(s),))
            rf = self.__cf.fetchone()
            if rf is None:
                return None
            return (rf[0],) + self.select_package_by_id(rf[1])

    def iterate_on_select(self, select='', data=()):
        self.__cf.execute('SELECT name,mode,tartype,uid,gid,uname,gname,other_data,package_id FROM file '
                          + select, data)
        rf = self.__cf.fetchone()
        while rf is not None:
            rf = list(rf)
            if isinstance(rf[2], BufferType):
                rf[2] = str(rf[2])
            if rf[2] == tarfile.REGTYPE:
                if self.multi_hash_p:
                    rf[7] = db.select_hash_by_id(rf[7])
                else:
                    if isinstance(rf[7], BufferType):
                        rf[7] = str(rf[7])
                    rf[7] = (None, rf[7], None)
            yield rf
            rf = self.__cf.fetchone()

    def scan_by_hash(self, a, hash):
        # FIXME no multi hash support here
        assert isinstance(hash[1], str)
        self.__cf.execute('SELECT name,package_id FROM file  WHERE other_data = ? ', (dbapi.Binary(hash[1]),))
        rf = self.__cf.fetchone()
        if rf is None:
            return {}
        else:
            p = self.select_package_by_id(rf[1]) + (self.dbname,)
            return {'MV': (a, '<-', self.CF.decompress(rf[0]), ':') + p}

    def scan(self, i, hashes=None, root='/'):
        """scan file to see if it was modified in any way. Returns a dictionary (code,reason)"""
        # if os.path.isfile(i) and (not os.path.islink(i)) and (not os.access(i, os.R_OK)):
        #    return {'CANT_READ':(i,)}

        name, mode, tartype, uid, gid, uname, gname, data = stat_to_tar(root + i)

        if tartype == 'SOCKET':  # it is a socket
            return {'SOCKET': (i,)}

        ls_l = tarinfo_to_ls(tartype, mode)
        assert isinstance(mode, IntType)
        if tartype == tarfile.REGTYPE:
            if hashes is None:
                data = helper_hashes(root + i, m=self.multi_hash_p)
            else:
                data = hashes
        if DEBUG > 1:
            print '# scanning ', i, tartype, repr(data)

        cname = self.CF.compress(name)
        self.__cf.execute('SELECT name,mode,tartype,uid,gid,uname,gname,other_data,package_id FROM file  WHERE name = ? ', (dbapi.Binary(cname),))
        rf = self.__cf.fetchone()
        # did not find by pathname
        if rf is None:
            if tartype == tarfile.DIRTYPE:
                if uid == 0 and gid == 0 and mode == 0o755:
                    # the database does not contain this kind of directories
                    return {'DIR': (i,)}
                else:
                    return {'DIR_CHMOD': (ls_l, uname, gname)}
            return {'U': (i,)}

        # did find this pathname
        # lets scan and see if we can find a good explanation
        while rf:
            rfname, rfm, rft, rfuid, rfgid, rfuname, rfgname, rfd, rfi = sqlite_towards_tarinfo(rf, self.CF)

            if rft == tarfile.REGTYPE:
                if self.multi_hash_p:
                    rfd = self.select_hash_by_id(rfd)
                else:
                    rfd = (None, str(rfd), None)

            p = self.select_package_by_id(rfi) + (self.dbname,)

            rf_ls_l = tarinfo_to_ls(rft, rfm)

            code_reason = compute_code_reason(
                (name, mode, tartype, uid, gid, uname, gname, data),
                (rfname, rfm, rft, rfuid, rfgid, rfuname, rfgname, rfd),
                package=p, root=root)
            assert code_reason

            if DEBUG > 1:
                print '#code_reason for pair', name, rfname, code_reason

            if 'OK' in code_reason:
                return code_reason

            if rft == tarfile.REGTYPE and 'ED' not in code_reason:
                return code_reason

            rf = self.__cf.fetchone()
        return code_reason


def iterate_sorted_names(DBs, select='ORDER BY name', data=()):
    def c(a, b):
        return -cmp(a[0][0], b[0][0])
    its = []
    for f in DBs:
        if isinstance(f, StringType):
            db = hashdb(f)
        else:
            db = f
        i = db.iterate_on_select(select, data)
        try:
            r = i.next()
            its.append((r, i, db))
        except StopIteration:
            pass
    while its:
        its.sort(c)
        r, i, db = its.pop()
        yield r, db
        try:
            r = i.next()
            its.append((r, i, db))
        except StopIteration:
            pass


# codes returned by hashdb.__scan
scan_result_codes = {
    'U': 'This file is not in the database(s).',
    'DIR': 'This is a directory with standard ownership and permissions.',
    'DIR_CHMOD': 'This is a directory with strange ownership and permissions.',
    'OK': 'This file is identical to what is shipped inside the Debian package',
    'TYPE': 'There is a file with such name in a package, but it is a different filesystem object.',
    'SOCKET': 'This file is a socket, and debforensic does not have a clue about sockets.',
    'ED': 'This is a regular file, and its content was modified.',
    'CH': 'This is a nonregular file, and it was modified.',
    'CHMOD': 'The permissions of this file were changed.',
    'CHOWN': 'The ownership of this file was changed.',
    'CHGRP': 'The group ownership of this file was changed.',
    'MV': 'This regular file was found in a package, but with another name.',
    'RM': 'This file is listed in this package, but is not present in the filesystem.',
    'DIVERT': 'This file was diverted.',
    'CANT_READ': 'This file cannot be read.',
    'NOT_REG': 'This is not a regular file.',  # this is used in scan() where we do not investigate further
    'DPKG-I': 'This file is in a package that is here installed, but the package is not in the database(s).',
    'EQ': 'This file is identical to a file in this package, according to the database(s), but this package is not installed.',
    'MAYBE': 'This file is not in the database(s); it is here listed as being part of this package.',
    'NOT_EXISTS': 'This file does not exists.',
    'BROKEN_HARDLINK': 'These two files are hardlinked in the package, but are not in the filesystem. This is though a minor problem.'
}


def compute_code_reason(xxx_todo_changeme, xxx_todo_changeme1,
                        package=(), root='/', ls_l=None):
    "compare two files, and explain what is different"
    (name, mode, tartype, uid, gid, uname, gname, data) = xxx_todo_changeme
    (rfname, rfm, rft, rfuid, rfgid, rfuname, rfgname, rfd) = xxx_todo_changeme1
    rf_ls_l = tarinfo_to_ls(rft, rfm)
    if ls_l is None:
        ls_l = tarinfo_to_ls(tartype, mode)

    p = package
    if p != () and p[0][0] != ':':
        p = (':',) + p

    # if tartype == 'SOCKET': #actually this will never trigger
    #    return {'SOCKET':(name,)}

    if rft == tarfile.LNKTYPE:
        code_reason = {'BROKEN_HARDLINK': (name, '<->', str(rfd),) + p}
        try:
            rfstat = os.stat(root + str(rfname))
            linkstat = os.stat(root + str(rfd))
            if rfstat[ST_DEV] == linkstat[ST_DEV] and rfstat[ST_INO] == linkstat[ST_INO]:
                return {'OK': (name,) + p}
            a = open(root + str(rfname))
            b = open(root + str(rfd))
            c, d = 1, 1
            while c == d and c:
                c = a.read(1000)
                d = b.read(1000)
            if c or d:
                code_reason['ED'] = (name,) + p
        except OSError as e:
            code_reason['CANT_READ'] = (str(e),)
        except IOError as e:
            code_reason['CANT_READ'] = (str(e),)
        return code_reason

    if rft == tartype and rfname == name and mode == rfm and data == rfd and uid == rfuid and gid == rfgid:
        return {'OK': (name,) + p}

    code_reason = {}

    if rfname != name:
        code_reason['MV'] = (name, '<-', rfname) + p

    if rft != tartype:
        code_reason['TYPE'] = (name, ls_l, '<-', rf_ls_l) + p
        return code_reason  # not much point in checking uig and gid

    if rft == tarfile.REGTYPE:
        assert isinstance(data, TupleType) and len(data) == 3
        assert isinstance(rfd, TupleType) and len(rfd) == 3
        if data[1] is None:
            code_reason['CANT_READ'] = (name,)
        elif (data[0] is not None and rfd[0] is not None and data[0] != rfd[0]) or\
             (data[2] is not None and rfd[2] is not None and data[2] != rfd[2]) or\
             (data[1] != rfd[1]):
            if DEBUG:
                code_reason['ED'] = (name, 'SHA1:' + sha1_to_hex(data[1]), '<-', 'SHA1:' + sha1_to_hex(rfd[1])) + p
            else:
                code_reason['ED'] = (name,) + p
    else:
        if data != rfd:
            code_reason['CH'] = (name, data, '<-', rfd) + p

    if mode != rfm:
        code_reason['CHMOD'] = (name, ls_l, '<-', rf_ls_l) + p

    if uname is not None:  # actually this is never None
        if rfuname != uname:
            code_reason['CHOWN'] = (name, uname, '<-', rfuname) + p
    else:
        if rfuid != uid:
            code_reason['CHOWN'] = (name, uid, '<-', rfuid) + p

    if gname is not None:
        if rfgname != gname:
            code_reason['CHGRP'] = (name, gname, '<-', rfgname) + p
    else:
        if rfgid != gid:
            code_reason['CHGRP'] = (name, gid, '<-', rfgid) + p
    return code_reason


explained = []


def explain_scan(code_reason, root='/'):
    for code, reason in code_reason.items():
        assert isinstance(reason, TupleType)
        if code not in ('OK', 'DIR') or VERBOSE:
            if DEBUG:
                # def f(x):
                #    if x == ':' : return x
                #    else: return repr(x)
                print code + ' ' + string.join(map(repr, reason))
            else:
                print code + '  ' + root + string.join(reason, '  ')
            if (INFO or VERBOSE or DEBUG) and code not in explained:
                print '#', code, '=', scan_result_codes.get(code, 'sorry, no help (yet).')
                explained.append(code)
        if code in ('OK', 'DIR'):
            return False
    return True


def scan(a, DBs, root='/'):
    "optimize scanning in multiple DBs by computing hashes only once"
    i = root + a
    if not os.path.exists(i):
        return {'NOT_EXISTS': (a,)}
    if os.path.isfile(i) and not os.path.islink(i):
        h = helper_hashes(i)
    else:
        # here we do not investigate further ... --forensic instead does
        return {'NOT_REG': (i,)}
    for db in DBs:
        c_r = db.scan(a, hashes=h, root=root)
        if 'U' not in c_r:
            return c_r
    if h[1]:
        for db in DBs:
            c_r = db.scan_by_hash(a, h)
            if c_r:
                return c_r
    elif h[1] is None:
        return {'CANT_READ': (i,)}
    else:
        assert(False)
    return {'U': (a,)}


def recurse_scan(a, DBs, root='/'):
    assert isinstance(a, StringType)
    failures = 0
    i = root + a
    if os.path.isdir(i):
        code_reason = scan(a, DBs, root)
        if explain_scan(code_reason, root):
            failures += 1
        for dirpath, dirnames, filenames in os.walk(i):
            for n in filenames + dirnames:
                f = os.path.join(dirpath, n)
                code_reason = scan(f[len(root):], DBs, root)
                if explain_scan(code_reason, root):
                    failures += 1
    elif os.path.exists(i):
        code_reason = scan(a, DBs, root)
        if explain_scan(code_reason, root):
            failures += 1
    else:
        explain_scan({'NOT_EXISTS': (a,)}, root)
    return failures


def add(pack, H):
    pack = abspath(pack)
    if os.path.isdir(pack):
        pack = pack + '/Packages'
    if os.path.basename(pack) == 'Packages':
        assert os.path.isfile(pack)
        dist = os.path.dirname(pack)
        base = dist.split('/')
        try:
            a = base.index('dists')
        except ValueError:
            sys.stderr.write('Error: pathname "%s" does not contain "dists"\n' % pack)
        base = string.join(base[:a], '/')
        RELEASE_FILE = (dist + '/Release')
        assert os.path.isfile(RELEASE_FILE)
        RELEASE_DB = parse_release(RELEASE_FILE)
        for A, B in RELEASE_DB.items():
            H.insert_info('Release/' + A, B)
        f = open(pack)
        for a in f:
            a = a.rstrip('\n')
            if a[:10] == 'Filename: ':
                a = base + '/' + a[10:]
                if not os.path.isfile(a):
                    sys.stderr.write('Package missing! ' + a + '\n')
                else:
                    H.add(a)
    elif pack[-4:] == '.deb':
        H.add(pack)
    else:
        sys.stderr.write("debforensic: dont know how to add " + pack + "\n")


def create(dbname):
    if multi_hash_p and sha256new is None:
        sys.stderr.write("When multi_hash_p is enabled, use python 2.5 or above\n")
        sys.exit(1)
    if os.path.exists(dbname):
        sys.stderr.write(sys.argv[0] + ': will not overwrite already existing ' + dbname + '\n')
        sys.exit(1)
    os.popen("sqlite3 '" + dbname + "'", 'w').write(sql_scheme)
    H = hashdb(dbname)
    if multi_hash_p:
        H.insert_hash__((md5new().digest(), sha1new().digest(), sha256new().digest()), 0)
    H.commit()


def test(dbname):
    if not os.path.exists(dbname):
        create(dbname)
    H = hashdb(dbname)
    print 'insert 0.20  as ', H.hash_deb('/home/debdev/debdelta/debdelta_0.20_i386.deb')
    print 'insert 0.22  as ', H.hash_deb('/home/debdev/debdelta/debdelta_0.22_i386.deb')
    print "scan('/usr/share/doc/debdelta/README.gz')"
    print H.scan('/usr/share/doc/debdelta/README.gz')
    print "scan('/usr/share/doc/debdelta/')"
    r = H.scan('/usr/share/doc/debdelta/')
    print 'result ', r
    print "recurse_scan('/usr/share/doc/debdelta/')"
    r = recurse_scan('/usr/share/doc/debdelta/', (H,))
    print 'result ', r
    s = sha.new(open("/usr/share/doc/debdelta/copyright").read()).digest()
    print 'find by sha1 ', H.find_by_sha1(s)
    # print parse_release('/var/lib/apt/lists/www.debian-multimedia.org_dists_etch_Release')
    # print parse_release('/var/lib/apt/lists/volatile.debian.net_debian-volatile_dists_etch_volatile_Release')


def index(dbname):
    os.popen("sqlite3 '" + dbname + "'", 'w').write(sql_scheme_indexes)


def forensic(DBs, root='/'):
    #import Queue
    #import threading
    #filesysqueue = Queue.Queue()
    # danger Will Robinson! this works fine only if all DBs use the same CompressFilename
    CF = CompressFilename()

    def iterate_from_prefix(base, npref, filelist):
        if not os.access(root + base, os.R_OK | os.X_OK):
            print '# cannot enter into dir ', repr(root + base)
            return
        for a in os.listdir(root + base):
            a = base + a
            i = root + a
            if os.path.isdir(i) and not os.path.islink(i):
                a = a + '/'
                n = CF.find_prefix(a)
                if not n:
                    print '# skipping directory tree ', repr(i)
                elif n == npref:
                    iterate_from_prefix(a, npref, filelist)
            else:
                r = list(stat_to_tar(i))
                if r[2] == 'SOCKET':
                    print '# ignoring socket ', i
                    break
                if os.path.isfile(i) and not os.path.islink(i):
                    if not os.access(i, os.R_OK):
                        if DEBUG:
                            print '# cannot scan file ', repr(i)
                        r[-1] = (None, None, None)
                    else:
                        r[-1] = helper_hashes(i)
                filelist.append((CF.compress(a), r))

    def iterate_sorted_dirs():  # this is not optimized, but it works fine
        for pref in CF.common_file_prefixes:
            if pref == '':
                continue  # avoid stuff in nonstandard directories
            npref = CF.find_prefix(pref)
            assert pref == CF.common_file_prefixes[npref]
            filelist = []
            iterate_from_prefix(pref, npref, filelist)
            filelist.sort()
            for c, r in filelist:
                yield c, r

    #t = threading.Thread(target=iterate_sorted_dirs)
    # t.setDaemon(True)
    # t.start()

    diversions_from, diversions_to = scan_diversions()
    diversions_candidates = {}  # files in the database that may explain diverted files
    installed_packages = parse_status(root, DBs)

    def express_package(package, db, installed_p=None):
        if installed_p and (installed_p or (package, db.dbname) in installed_packages):
            return (':',) + installed_packages[(package, db.dbname)] + (db.dbname,)
        else:
            return (':not-installed:',) + db.select_package_by_id(package) + (db.dbname,)

    iterate_db = iterate_sorted_names(DBs)
    iterate_sys = iterate_sorted_dirs()

    def db_next():
        try:
            l, db = iterate_db.next()
        except StopIteration:
            return None, None, None, None
        rf = sqlite_towards_tarinfo(l, db.CF)
        return l[0], rf[:8], db, l[-1]

    def sys_next():
        try:
            return iterate_sys.next()
        except StopIteration:
            return None, None

    # stuff that is outside the standard directory trees
    if DEBUG:
        print '#files in non standard directories follow'
    rfcn, rf, db, package = db_next()
    while rfcn is not None and ord(rfcn[0][0]) == 1:
        i = root + rf[0]
        if os.path.exists(i):
            if rf[0] in diversions_from:
                divert_to, divert_pack = diversions_from[rf[0]]
                a = diversions_candidates.get(divert_to, [])
                diversions_candidates[divert_to] = a.append((rf, db, package))
            elif (package, db.dbname) in installed_packages:
                rsys = list(stat_to_tar(i))
                if os.path.isfile(i) and not os.path.islink(i):
                    rsys[-1] = helper_hashes(i)
                a = express_package(package, db, True)
                code_reason = compute_code_reason(rsys, rf, a, root)
                explain_scan(code_reason, root)
        rfcn, rf, db, package = db_next()

    # stuff that is in the standard directory trees
    removed_files = {}
    extra_files = {}
    extra_sha1 = {}
    if DEBUG:
        print '#files in standard directories follow'
    did_prefix = None
    rsyscn = True
    while rsyscn is not None and rfcn is not None:  # main loop, consumes both iterators
        if DEBUG:
            n = ord(rfcn[0]) - 1
            if n != did_prefix:
                print '# files in the directory tree ', CF.common_file_prefixes[n]
                did_prefix = n
        rsyscn, rsys = sys_next()
        while rsyscn is not None:
            if rsys[0] in diversions_to:
                divert_from, divert_pack = diversions_to[rsys[0]]
                diversions_to[rsys[0]] = (divert_from, (divert_pack, rsys))
                if DEBUG:
                    explain_scan({'DIVERT': (divert_from, '->', rsys[0], 'by', divert_pack)})
            elif rfcn > rsyscn:
                if rsys[0] in installed_packages:
                    explain_scan({'MAYBE': (rsys[0], ':local:') + installed_packages[rsys[0]]})
                else:
                    explain_scan({'U': (rsys[0],)})  # fixme : maybe it was moved away
                    extra_files[rsys[0]] = rsys
                    if rsys[2] == tarfile.REGTYPE:
                        extra_sha1[rsys[-1][1]] = rsys
            else:
                break
            rsyscn, rsys = sys_next()
        # at this point, we know that rsys is not a diversion and that rfcn <= rsyscn
        while rfcn is not None:
            if rf[0] in diversions_from:
                divert_to, divert_pack = diversions_from[rf[0]]
                if divert_to not in diversions_candidates:
                    diversions_candidates[divert_to] = []
                diversions_candidates[divert_to].append((rf, db, package))
            elif rfcn < rsyscn:
                if (package, db.dbname) in installed_packages:
                    a = express_package(package, db, True)
                    # if rf[2] == tarfile.REGTYPE: #fixme: may track moved files by sha1
                    explain_scan({'RM': (rf[0],) + a})
                    removed_files[rf[-1]] = rf
            else:
                break
            rfcn, rf, db, package = db_next()
        code_reason = None
        best_code_reason = None
        while rfcn is not None and rfcn == rsyscn:
            if (package, db.dbname) in installed_packages:
                a = express_package(package, db, True)
                code_reason = compute_code_reason(rsys, rf, a, root)
                if 'OK' in code_reason:
                    best_code_reason = code_reason
            elif best_code_reason is None:
                a = express_package(package, db, False)
                code_reason = compute_code_reason(rsys, rf, a, root)
                if 'OK' in code_reason:
                    del code_reason['OK']
                    code_reason['EQ'] = (rsys[0],) + a
                if rsys[0] in installed_packages:
                    code_reason['DPKG-I'] = (rsys[0], ':local:') + installed_packages[rsys[0]]
            rfcn, rf, db, package = db_next()
        if best_code_reason is not None:
            explain_scan(best_code_reason, root)
        elif code_reason is not None:
            explain_scan(code_reason, root)

    # check diversions
    if DEBUG:
        print '# diversions follow'
    for divert_to in diversions_to:
        divert_from, divert_info = diversions_to[divert_to]
        if not os.path.exists(root + divert_to):
            print "# non existent target '%s' , diverted from file '%s' package '%s'" % (divert_to, divert_from, divert_info)
        elif isinstance(divert_info, StringType):
            print "# out of debforensic scope, target '%s' , diverted from file '%s' package '%s'" % (divert_to, divert_from, divert_info)
        else:
            divert_pack, rsys = divert_info
            if rsys[0] not in diversions_candidates:
                print "# target '%s' is diverted from file '%s' by package '%s' , but the file is not in the database(s)." % (divert_to, divert_from, divert_info)
                explain_scan({'U': (rsys[0],)}, root)
            else:
                for rf, db, package in diversions_candidates[rsys[0]]:
                    a = express_package(package, db)
                    code_reason = compute_code_reason(rsys, rf, a, root)
                    if 'MV' in code_reason:
                        code_reason['DIVERT'] = code_reason['MV'] + ('BY:' + divert_pack,)
                        del code_reason['MV']
                    if code_reason.keys() == 'DIVERT':
                        break
                if DEBUG:
                    print "# target '%s' is a diverted from file '%s' package '%s'" % (divert_to, divert_from, divert_info)
                explain_scan(code_reason, root)


if __name__ == '__main__':
    #argv = debugging_argv or sys.argv
    if len(sys.argv) <= 1:
        help()
        raise SystemExit(0)

    RELEASE_FILE = None
    RELEASE_DB = {}
    DEBUG = 0
    VERBOSE = 0
    INFO = False
    RECURSIVE = False
    ACT = True
    dbname = []
    cmd = None
    JUSTHELP = False
    CHROOT = '/'

    try:
        (opts, argv) = getopt.getopt(sys.argv[1:], 'hvdriD:R:',
                                     ('help', 'debug', 'verbose', 'no-act', 'release=', 'db=',
                                      'create', 'scan', 'add', 'dump', 'test', 'index', 'forensic',
                                      'compress', 'info', 'recursive', 'chroot='))
    except getopt.GetoptError as a:
        sys.stderr.write(sys.argv[0] + ': ' + str(a) + '\n')
        raise SystemExit(2)

    for o, v in opts:
        if o == '-v' or o == '--verbose':
            VERBOSE += 1
        elif o == '-d' or o == '--debug':
            DEBUG += 1
        elif o == '-r' or o == '--recursive':
            RECURSIVE = True
        elif o == '-i' or o == '--info':
            INFO = True
        elif o == '--no-act':
            ACT = False
        elif o == '-D' or o == '--db':
            dbname.append(v)
        elif o == '--chroot':
            CHROOT = v
        elif o == '-R' or o == '--release':
            RELEASE_FILE = v
            RELEASE_DB = parse_release(RELEASE_FILE)
        elif o == '--help' or o == '-h':
            JUSTHELP = True
        elif o[:2] == '--' and o[2:] in __help__.keys():
            if cmd:
                sys.stderr.write(' option ', o, 'is unacceptable after', cmd)
                raise SystemExit(1)
            else:
                cmd = o[2:]
        else:
            sys.stderr.write(' option ', o, 'is unknown, try --help')
            raise SystemExit(1)

    if JUSTHELP:
        help(cmd)
        raise SystemExit(0)

    if not cmd and INFO:
        print 'This is the list of result codes printed by --scan or --forensic :'
        for a, b in scan_result_codes.items():
            print a, ' = ', b
        raise SystemExit(0)

    if not cmd:
        sys.stderr.write('Need a command. Read --help.\n')
        raise SystemExit(1)

    if not dbname:
        sys.stderr.write('Need a database. Use --db DB . Read --help .\n')
        raise SystemExit(1)
    elif len(dbname) > 1 and not (cmd == 'dump' or cmd == 'scan' or cmd == 'forensic'):
        sys.stderr.write('Provide only one database for --' + cmd + '.\n')
        raise SystemExit(1)

    if argv and not (cmd == 'scan' or cmd == 'dump' or cmd == 'add' or cmd == 'create'):
        sys.stderr.write('Do not provide arguments for --' + cmd + '.\n')
        raise SystemExit(1)

    if dbapi is None:
        sys.stderr.write("Please install the package 'python-pysqlite2'\n")
        raise SystemExit(1)

    if not (cmd == 'dump' or cmd == 'scan' or cmd == 'forensic'):
        dbname = dbname[0]

    if cmd == "test":
        test(dbname)
        sys.exit(0)

    elif cmd == "index":
        index(dbname)
        sys.exit(0)

    elif cmd == "create":
        create(dbname)
        if argv:
            H = hashdb(dbname)
            for i in argv:
                add(i, H)
        sys.exit(0)

    elif cmd == "add":
        assert os.path.isfile(dbname)
        H = hashdb(dbname)
        for i in argv:
            add(i, H)

    elif cmd == "forensic":
        H = map(hashdb, dbname)
        forensic(H, CHROOT)

    elif cmd == "scan":
        H = map(hashdb, dbname)
        if RECURSIVE:
            for i in argv:
                recurse_scan(i.lstrip('/'), H, root=CHROOT)
        else:
            for i in argv:
                code_reason = scan(i.lstrip('/'), H, root=CHROOT)
                explain_scan(code_reason)

    elif cmd == "dump_p":
        assert os.path.isfile(dbname)
        H = hashdb(dbname)
        c = H.dump_flat_all()
        for i in c:
            j = list(i)
            #j[4]=  tarinfo_to_ls(j[4] , j[5])
            # j[4] = '0%o' & j[4] ???
            r = list(sqlite_towards_tarinfo(i[3:], H.CF))
            r.pop()  # discard package_index
            if r[2] == tarfile.REGTYPE and not H.multi_hash_p:
                r.append('SHA1:' + sha1_to_hex(r.pop()))
            ls_l = tarinfo_to_ls(r[2], r[1])
            j = j[:3] + [r[0], ls_l] + r[5:]
            print string.join(map(str, j), '\t')

    elif cmd == "dump":
        if argv:
            assert len(argv) == 1
            CF = CompressFilename()
            select = ' WHERE name = ?'
            data = (dbapi.Binary(CF.compress(argv[0].lstrip('/'))),)
            c = iterate_sorted_names(dbname, select, data)
        else:
            c = iterate_sorted_names(dbname)
        for l, db in c:
            r = list(sqlite_towards_tarinfo(l, db.CF))
            pid = r.pop()  # discard package_index
            if r[2] == tarfile.REGTYPE:
                m = r.pop()
                assert isinstance(m, TupleType) and len(m) == 3
                r.append('SHA1:' + sha1_to_hex(m[1]))
                if db.multi_hash_p:
                    r.append('SHA256:' + sha1_to_hex(m[2]))
                    r.append('MD5:' + sha1_to_hex(m[0]))
            ls_l = tarinfo_to_ls(r[2], r[1])
            r = [r[0], ls_l] + r[5:] + list(db.select_package_by_id(pid)) + [db.dbname]
            print string.join(map(repr, r), '\t')

    else:
        sys.stderr.write("Sorry this command is yet unimplemented: " + cmd + '\n')
        sys.exit(1)
